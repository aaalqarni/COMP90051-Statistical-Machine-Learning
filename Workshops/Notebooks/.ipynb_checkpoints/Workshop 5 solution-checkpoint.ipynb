{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP90051 Workshop 5\n",
    "## The Perceptron and PyTorch  \n",
    "***\n",
    "In this worksheet, we'll implement the perceptron (a building block of neural networks) from scratch. \n",
    "Our key objectives are:\n",
    "\n",
    "* to review the steps involved in the perceptron training algorithm\n",
    "* to assess how the perceptron behaves in two distinct scenarios (separable vs. non-separable data)\n",
    "* learn how to use PyTorch, a high performance deep learning API, to implement the perceptron with automatic differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Synthetic data set\n",
    "We'll use the built-in `make_classification` function from `sklearn` to generate a synthetic binary classification data set.\n",
    "The main advantage of using synthetic data is that we have complete control over the distribution. \n",
    "This is useful for studying machine learning algorithms under specific conditions.\n",
    "In particular, we'll be varying the *degree of separability* between the two classes by adjusting the `class_sep` parameter below.\n",
    "To begin, we'll work with a data set that is almost linearly separable (with `class_sep = 1.75`).\n",
    "\n",
    "**Note:** In this worksheet we deviate from the standard `0`/`1` encoding for binary class labels used in `sklearn`. \n",
    "We use `-1` in place of `0` for the \"negative\" class to make the mathematical presentation of the perceptron algorithm easier to digest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGURE_RESOLUTION = 128\n",
    "plt.rcParams['figure.dpi'] = FIGURE_RESOLUTION\n",
    "\n",
    "def create_toy_data(n_samples=150, class_sep=1.75):\n",
    "    X, y = make_classification(n_samples=n_samples, n_features=2, n_informative=2, \n",
    "                               n_redundant=0, n_clusters_per_class=1, flip_y=0,\n",
    "                               class_sep=class_sep, random_state=12)\n",
    "    y[y==0] = -1 # encode \"negative\" class using -1 rather than 0\n",
    "    plt.plot(X[y==-1,0], X[y==-1,1], \".\", label=\"$y = -1$\")\n",
    "    plt.plot(X[y==1,0], X[y==1,1], \".\", label=\"$y = 1$\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"$x_0$\")\n",
    "    plt.ylabel(\"$x_1$\")\n",
    "    plt.show()\n",
    "\n",
    "    return X,y\n",
    "\n",
    "X, y = create_toy_data(class_sep=1.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Is the perceptron a suitable classifier for this data set?\n",
    "\n",
    "**Answer:** *Strictly speaking, the perceptron is only guaranteed to converge to a \"reasonable\" solution if the data is linearly seperable.\n",
    "This data is not quite linearly separable, so one could argue that the perceptron is unsuitable.*\n",
    "  \n",
    "In preparation for training and evaluating a perceptron on this data, we randomly partition the data into train/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=90051)\n",
    "print(\"Training set has {} instances. Test set has {} instances.\".format(X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Definition of the perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from lectures that a perceptron is a linear binary classifier which maps an input vector $\\mathbf{x} \\in \\mathbb{R}^D$ to a binary output $y \\in \\{-1,1\\}$ given by\n",
    "$$\n",
    "\\begin{align*}\n",
    "f(\\mathbf{x}; \\mathbf{w}, b) &= \\begin{cases}\n",
    "    1 & \\mathrm{if} \\ s(\\mathbf{x}; \\mathbf{w}, b) \\geq 0, \\\\\n",
    "    -1 & \\mathrm{otherwise},\n",
    "\\end{cases}\n",
    "\\end{align*}\n",
    "$$\n",
    "where $s(\\mathbf{x}; \\mathbf{w}, b) = \\mathbf{w} \\cdot \\mathbf{x} + b$. \n",
    "Here $\\mathbf{w} \\in \\mathbb{R}^D$ is a vector of weights (one for each feature) and $b$ is the bias term. Note that for this worksheet we are including an explicit bias, rather than incorporating it as a constant column in $\\mathbf{X}$.\n",
    "\n",
    "Let start by implementing the weighted sum function $s(\\mathbf{x}; \\mathbf{w}, b)$ below. This is the 'inner product' $\\langle\\mathbf{w}, \\mathbf{x}\\rangle = \\sum_i w_i x_i$, which captures the geometrical alignment of the weight and instance vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_sum(X, w, b):\n",
    "    \"\"\"\n",
    "    Returns an array containing the weighted sum s(x) for each instance x in the feature matrix\n",
    "    \n",
    "    Arguments:\n",
    "    X : numpy array, shape: (n_instances, n_features)\n",
    "        feature matrix\n",
    "    w : numpy array, shape: (n_features,)\n",
    "        weights vector\n",
    "    b : float\n",
    "        bias term\n",
    "    \"\"\"\n",
    "    return np.dot(X, w) + b # fill in\n",
    "\n",
    "def predict(X, w, b):\n",
    "    \"\"\"\n",
    "    Returns an array containing the predicted binary labels (-1/1) for each instance in the feature matrix\n",
    "    \n",
    "    Arguments:\n",
    "    X : numpy array, shape: (n_instances, n_features)\n",
    "        feature matrix\n",
    "    w : numpy array, shape: (n_features,)\n",
    "        weights vector\n",
    "    b : float\n",
    "        bias term\n",
    "    \"\"\"\n",
    "    return np.where(weighted_sum(X, w, b) >= 0, 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Perceptron training algorithm\n",
    "\n",
    "We will now implement the Perceptron training algorithm first proposed by Rosenblatt in 1957. \n",
    "\n",
    "This is an online algorithm in the sense that it examples one point $\\mathbf{x}_t$ at a time. At each stage, the algorithm maintains a weight vector $\\mathbf{w}_t$ which defines the learned (hyper)plane separating the two classes. For convenience one typically starts with $\\mathbf{w}_0 = 0$. The label of the point $\\mathbf{x}_t$ is predicted using the sign of the dot product: $\\hat{y}_t = \\mathrm{sign}(\\mathbf{w}_t \\cdot \\mathbf{x}_t)$. If $\\mathbf{x}_t$ is misclassified, $y_t \\mathbf{x}_t \\cdot \\mathbf{w}_t$ is negative and we make a correction to the weight vector $\\mathbf{w}_{t+1} = \\mathbf{w}_t + \\eta y_t \\mathbf{x}_t$ for some learning rate $\\eta >0$. To motivate this, consider the dot product of the weight vector after the update with the misclassified instance: \n",
    "\n",
    "\\begin{align}\n",
    "y_t (\\mathbf{w}_t + \\eta y_t \\mathbf{x}_t) \\cdot \\mathbf{x}_t &= y_t \\mathbf{w}_t \\cdot \\mathbf{x}_t + \\eta ||\\mathbf{x}_t ||^2\\\\\n",
    "&\\geq y_t \\mathbf{w}_t \\cdot \\mathbf{x}_t\n",
    "\\end{align}\n",
    "\n",
    "So we reduce the severity of the error by an additive correction $\\eta || \\mathbf{x}_t ||^2$. We repeat this procedure until convergence or termination after a set limit of iterations. Pseudocode of the algorithm is shown below (taken from _Foundations of Machine Learning, Mohri, 2019_).\n",
    "\n",
    "<img src=\"https://i.imgur.com/N6NZrAC.png\" alt=\"Perceptron alg.\" width=\"750\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** After iterating through all of the training instances $t=[1, \\ldots, T]$, we have completed one *epoch*. The above pseudocode runs for one epoch. Typically, multiple epochs are required to get close to the optimal solution.\n",
    "\n",
    "The above training procedure is equivalent to performing sequential gradient descent on the following objective function:\n",
    "\n",
    "\\begin{align}\n",
    "    F(\\mathbf{w}) &= \\frac{1}{T} \\sum_{t=1}^T \\max\\left(0, -y_t (\\mathbf{w} \\cdot \\mathbf{x}_t)\\right) \\\\\n",
    "    \\mathbf{w}_{t+1} &\\leftarrow \\mathbf{w}_t - \\eta \\nabla_{\\mathbf{w}} F(\\mathbf{w}) \n",
    "\\end{align}\n",
    "\n",
    "To motivate the form of $F(\\mathbf{w})$, note that if $\\mathbf{x}_t$ is misclassified, $-y_t \\mathbf{w}_t \\cdot \\mathbf{x}_t > 0$. In this case the gradient is $\\nabla_{\\mathbf{w}} F(\\mathbf{w}) = -y_t \\mathbf{x}_t$, and zero if the instance is correctly classified. Omitting technical details about the case where $\\mathbf{w}_t \\cdot \\mathbf{x}_t = 0$ (we can resolve the non-differentiability by working with _subgradients_), the stochastic online update becomes:\n",
    "\n",
    "$$ \\mathbf{w}_{t+1} \\leftarrow\n",
    "  \\begin{cases}\n",
    "    \\mathbf{w}_t + \\eta y_t \\mathbf{x}_t, & \\text{if } y_t\\left(\\mathbf{x}_t \\cdot \\mathbf{w}_t\\right) \\leq 0; \\\\\n",
    "    \\mathbf{w}_t, & \\text{if } y_t\\left(\\mathbf{x}_t \\cdot \\mathbf{w}_t\\right) > 0 \\\\\n",
    "  \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now write a function called `train` which implements sequential gradient descent. The function should implement the pseudocode shown above, repeated for `n_epochs`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, w, b, n_epochs=10, eta=0.1):\n",
    "    \"\"\"\n",
    "    Returns updated weight vector w and bias term b for\n",
    "    the Perceptron algorithm\n",
    "    \n",
    "    Arguments:\n",
    "    X : numpy array, shape: (n_instances, n_features)\n",
    "        feature matrix\n",
    "    y : numpy array, shape: (n_instances,)\n",
    "        target class labels relative to X\n",
    "    n_epochs : int\n",
    "        number of epochs (full sweeps through X)\n",
    "    w : numpy array, shape: (n_features,)\n",
    "        initial guess for weights vector w_0\n",
    "    b : float\n",
    "        initial guess for bias term b_0\n",
    "    eta : positive float\n",
    "        step size (default: 0.1)\n",
    "    \"\"\"\n",
    "    errors = 0\n",
    "    for t in range(n_epochs):\n",
    "        # loop over individual elements in X\n",
    "        for i in range(X.shape[0]):\n",
    "            yhat = predict(X[i,:], w, b) # fill in\n",
    "            if yhat != y[i]:\n",
    "                errors += 1\n",
    "                # Update if misclassified, else do nothing\n",
    "                w += eta * y[i] * X[i,:] # fill in\n",
    "                b += eta * y[i] # fill in\n",
    "                \n",
    "    print('Number of errors {} / {} iterations'.format(errors, n_epochs * X.shape[0]))\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your implementation by running it for 5 epochs.\n",
    "You should get the following result for the weights and bias term:\n",
    "`w = [ 0.78555827 -0.11419669]; b = 0.1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise weights and bias to zero\n",
    "w = np.zeros(X.shape[1]); b = 0.0\n",
    "\n",
    "w, b = train(X_train, y_train, w, b, n_epochs=5)\n",
    "print(\"w = {}; b = {}\".format(w, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've trained the perceptron, let's see how it performs.\n",
    "\n",
    "Below we plot the data (training and test sets) along with the decision boundary (which is defined by $\\{\\mathbf{x}: \\hat{\\mathbf{w}} \\cdot \\mathbf{x}= 0$\\})\n",
    "**Note:** It's not necessary to understand how the `plot_results` function works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(X_train, y_train, X_test, y_test, score_fn, threshold = 0):\n",
    "    # Plot training set\n",
    "    plt.plot(X_train[y_train==-1,0], X_train[y_train==-1,1], \".\", label=r\"$y=-1$, train\")\n",
    "    plt.plot(X_train[y_train==1,0], X_train[y_train==1,1], \".\", label=r\"$y=1$, train\")\n",
    "    plt.gca().set_prop_cycle(None) # reset colour cycle\n",
    "\n",
    "    # Plot test set\n",
    "    plt.plot(X_test[y_test==-1,0], X_test[y_test==-1,1], \"x\", label=r\"$y=-1$, test\")\n",
    "    plt.plot(X_test[y_test==1,0], X_test[y_test==1,1], \"x\", label=r\"$y=1$, test\")\n",
    "\n",
    "    # Compute axes limits\n",
    "    border = 1\n",
    "    x0_lower = X[:,0].min() - border\n",
    "    x0_upper = X[:,0].max() + border\n",
    "    x1_lower = X[:,1].min() - border\n",
    "    x1_upper = X[:,1].max() + border\n",
    "\n",
    "    # Generate grid over feature space\n",
    "    resolution = 0.01\n",
    "    x0, x1 = np.mgrid[x0_lower:x0_upper:resolution, x1_lower:x1_upper:resolution]\n",
    "    grid = np.c_[x0.ravel(), x1.ravel()]\n",
    "    s = score_fn(grid).reshape(x0.shape)\n",
    "\n",
    "    # Plot decision boundary (where s(x) == 0)\n",
    "    plt.contour(x0, x1, s, levels=[0], cmap=\"Greys\", vmin=-0.2, vmax=0.2)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"$x_0$\")\n",
    "    plt.ylabel(\"$x_1$\")\n",
    "    plt.show()\n",
    "    \n",
    "plot_results(X_train, y_train, X_test, y_test, lambda X: weighted_sum(X, w, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How well does the decision boundary separate the points in the two classes? How does it perform if you reduce the `class_sep` parameter in the `create_toy_dataset` function above?\n",
    "\n",
    "**Answer:** *The decision boundary is acceptable for `class_sep=1.75`, but very poor for `class_sep=0.5`.*\n",
    "\n",
    "To evaluate the perceptron quantitatively, we'll use the error rate (proportion of misclassified instances).\n",
    "The error rate is a reasonable evaluation measure to use for this data since the classes are well balanced.\n",
    "\n",
    "Complete the `evaluate` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X, y, w, b):\n",
    "    \"\"\"\n",
    "    Returns the proportion of misclassified instances (error rate)\n",
    "    \n",
    "    Arguments:\n",
    "    X : numpy array, shape: (n_instances, n_features)\n",
    "        feature matrix\n",
    "    Y : numpy array, shape: (n_instances,)\n",
    "        target class labels relative to X\n",
    "    w : numpy array, shape: (n_features,)\n",
    "        weights vector\n",
    "    b : float\n",
    "        bias term\n",
    "    \"\"\"\n",
    "    return np.mean(predict(X, w, b) != y) # fill in\n",
    "\n",
    "print(evaluate(X_train, y_train, w, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block above computes the error rate on the training data, which is not a good idea in general. (Why?)\n",
    "\n",
    "Compute the error rate on the test set instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluate(X_test, y_test, w, b)) # fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How does this compare to the error on the training set? Is it what you expected?\n",
    "\n",
    "**Answer:** *The error on the test set is a little higher than the error on the training set (for `class_sep=1.75`). This suggests we may have a problem with overfitting (but it's difficult to say for such a small sample size).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Repeat with class overlap\n",
    "By now you've probably concluded that the perceptron performs well on this data (`class_sep=1.75`), which is to be expected as it's roughly linearly separable. \n",
    "However, we know (from lectures) that the perceptron can fail on non-linearly separable data.\n",
    "To test this scenario, re-generate the synthetic data set with `class_sep=0.5` and repeat Sections 2–4.\n",
    "\n",
    "**Question:** What do you find? Pay particular attention to the error vs. training epochs (you may need to add a `print` command in the inner training loop). Do you notice anything unusual?\n",
    "\n",
    "**Answer:** As mentioned in the previous answer, the model becomes highly unstable—the optimisation algorithm doesn't really converge to a good \"approximate\" solution. As a result, the train/test errors fluctuate wildly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Move over numpy, hello PyTorch\n",
    "\n",
    "[Pytorch](https://pytorch.org/) is a open-source Python library designed for fast matrix computations on CPU/GPU. This includes both standard linear algebra and deep learning-specific operations. It is based on the neural network backend of the [Torch library](http://torch.ch/). A central feature of Pytorch is its use of Automatic on-the-fly differentiation ([Autograd](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)) to compute derivatives of (almost) all computations involving tensors, so we can make use of gradient-based updates to optimize some objective function. In this last section we will introduce some fundamental operations in Pytorch and reimplement the Perceptron algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the interface of pytorch, consider the following code which does some simple matrix operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Create matrices with entries drawn from the standard normal, and multiply them\n",
    "x_pt = torch.randn(size=[4,4])\n",
    "y_pt = torch.randn(size=[4,8])\n",
    "z_pt = torch.matmul(x_pt, y_pt)\n",
    "z_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the surface, this looks similar to numpy, albeit with a slightly different API. Behind the scenes, each time we evaluate a Pytorch operation, the library silently defines a new computation graph which is executed, and this is highly optimised on either CPU or GPU processors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not give a full tutorial of the basic operations here, other than to say that the basic API is extremely similar to numpy. Please take a few minutes to run through the [excellent introduction at the official Pytorch repository](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html). You may want to do this in your own time, either before or after the workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autograd\n",
    "To compute the gradients of tensors with respect to other tensors, a full record of operations performed on the Tensor must be retained. This can be achieved by setting the attribute `.requires_grad = True`. After the computation is finished, calling `.backward()` on the output tensor walks through the computation history in reverse order to automatically compute the gradients using a method based on the chain rule, which can be used for optimization of arbitrary loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 0\n",
    "x = torch.ones([2,3], requires_grad=True)\n",
    "loss = torch.exp(-(x-mu)**2/(2)).mean()\n",
    "loss.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient for the tensor `x` is accumulated into the `.grad` attribute. We would use this in some gradient based update rule, such as vanilla SGD. You might want to verify that the gradient above is correct, by calculating the gradient by hand.\n",
    "\n",
    "Atograd can be very useful when evaluating the derivatives of loss functions constructed as a sequence of nested operations (an example is the cross-entropy loss when using a neural network for classification) where the analytic derivative is difficult to compute symbolically.\n",
    "\n",
    "Note that autograd is **not** symbolic or numerical (finite-differences) differentiation, both of which have trouble handling gradients of relatively long nested functions. It is essentially a dynamic-programming approach to symbolic differentiation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back to the Perceptron\n",
    "\n",
    "Armed with this shiny deep learning API, let's rewrite the perceptron training algorithm. We have two options: just using the standard perceptron update formula, or providing torch with the loss function and letting it compute the gradient automatically. We'll go with the latter, a more general solution, which is similar to how you might train a logistic regerssion classification model, regression, counting likelihood etc. In these cases you would change the `loss =` line to reflect the different loss function, e.g., logistic cross entropy, squared error (Gaussian), Poisson loss for the three cases, respectively.\n",
    "\n",
    "Review the code below, and use the [PyTorch API](https://pytorch.org/docs/stable/torch.html#) to understand the operations. Some step are a little cryptic, and relate to enumerating over the training data, setting the shape of the tensors (e.g., `squeeze` which removes redundant dimensions of size 1, `requires_grad_` which flags a parameter for which `backward` will compute the gradient.) Take a look at the [SGD class, and other optimisers](https://pytorch.org/docs/stable/optim.html) and their various parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron_SGD_pytorch(X, y, n_epochs=10, eta=0.1):\n",
    "    \n",
    "    # Create iterable dataset in Torch format - technical details, \n",
    "    # don't worry too much about this!\n",
    "    X = torch.cat([torch.ones(X.shape[0],1), X], dim=1)\n",
    "    train_ds = torch.utils.data.TensorDataset(X, y)\n",
    "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=1)\n",
    "    \n",
    "    # Create trainable weight vector, tell Torch to track operations on w\n",
    "    w = torch.zeros(X.shape[1]).double().requires_grad_()\n",
    "    \n",
    "    # Setup the optimizer. This implements the basic gradient descent update\n",
    "    optimizer = torch.optim.SGD([w], lr=eta)\n",
    "    \n",
    "    for _ in range(n_epochs):\n",
    "        for i, (xi,yi) in enumerate(train_loader):\n",
    "            xi = torch.squeeze(xi)\n",
    "            \n",
    "            # Compute loss F(w)\n",
    "            loss = torch.max(torch.Tensor([0]), -yi * (torch.dot(w,xi)))\n",
    "            \n",
    "            loss.backward()               # Backward pass (compute parameter gradients)\n",
    "            optimizer.step()              # Update weight parameter using SGD\n",
    "            optimizer.zero_grad()         # Reset gradients to zero for next ieration\n",
    "        \n",
    "    w = w.detach()  # Tell Torch to stop tracking operations for autograd\n",
    "    print('Trained weights:', w)\n",
    "    return w.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the function above to verify it reaches a similar solution to the `numpy` code above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = train_perceptron_SGD_pytorch(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "\n",
    "plot_results(X_train, y_train, X_test, y_test, score_fn=lambda x: np.dot(x,w[1:])+w[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus tasks (optional)\n",
    "\n",
    "### Comparison with logistic regression\n",
    "We've seen that the perceptron is not robust to binary classification problems with overlapping classes. \n",
    "But how does logistic regression fare in this case?\n",
    "\n",
    "Adapt the code block above to fit a logistic regression model. To do so you will need to change the loss function to the cross entropy loss from the logistic regression model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence of perceptron\n",
    "In the following exercise we will work through a proof of the perceptron convergence algorithm. We make the following assumptions:\n",
    "* The feature vectors lie in a sphere of radius $R$: $\\vert \\mathbf{x}_n \\vert \\leq R \\; \\forall \\;n$, i.e. their maximum length is $R$.\n",
    "* The data is linearly separable with margin $2\\gamma > 0$. That is, there exists a unit normal vector to the hyperplane $\\mathbf{w}^*$ such that $y_i \\mathbf{w}^* \\cdot \\mathbf{x}_n \\geq \\gamma$ and $\\vert \\mathbf{w}^* \\vert = 1$. Note that $\\mathbf{w}^* \\cdot \\mathbf{x}_n $ can be thought of as the shortest (Euclidean) distance from the hyperplane to a given training instance $\\mathbf{x}_n$, as you will see when we study SVMs. We further assume that the hyperplane passes through the origin, so we can ignore the bias term (we could relax this assumption, just have to write bias terms everywhere). \n",
    "\n",
    "Given a sequence $\\mathbf{x}_1, \\ldots, \\mathbf{x}_T$ of $T$ instances, we want to find a bound on the total number of updates the Perceptron algorithm will make in this scenario. Let us only consider the subset of iterations $\\mathcal{K}$ of the $T$ rounds where the Perceptron makes an error, and we have to make an update. So we are interested in finding the number of updates $\\vert \\mathcal{K} \\vert$. Note we have a trivial bound of $\\vert \\mathcal{K} \\vert = T$ - where the algorithm makes an error at every iteration. We would like to obtain a more 'efficient' bound than this.\n",
    "\n",
    "1. Assume there is an error at iteration $k \\in \\mathcal{K}$ and we initialize $\\mathbf{w}_0 = \\mathbf{0}$. Prove that \n",
    "\n",
    "   $$ \\mathbf{w}^* \\cdot \\mathbf{w}_{k+1} \\geq (k+1) \\gamma $$\n",
    "   \n",
    "2. Use the fact that the instances $\\mathbf{x}_k$ are bounded to show that\n",
    "\n",
    "   $$ || \\mathbf{w}_k ||^2 \\leq k R^2 $$\n",
    "   \n",
    "3. Use the definition of the dot product, $\\mathbf{u} \\cdot \\mathbf{v} = \\vert \\mathbf{u} \\vert \\vert \\mathbf{v} \\vert \\cos \\theta $, where $\\theta$ is the angle between $\\mathbf{u}$ and $\\mathbf{v}$, to prove that\n",
    "\n",
    "   $$ \\vert \\mathbf{w}^* \\cdot \\mathbf{w}_k \\vert \\leq \\vert \\mathbf{w}^*\\vert \\vert \\mathbf{w}_k \\vert $$\n",
    "   \n",
    "Note we can also see this from the [Cauchy-Schwartz Inequality](https://en.wikipedia.org/wiki/Cauchy%E2%80%93Schwarz_inequality).\n",
    "\n",
    "4. Use the above inequalities to prove that the number of updates is bounded:\n",
    "   $$ k \\leq \\frac{R^2}{\\gamma^2} $$\n",
    "   \n",
    "In other words, no misclassified sample exists after at most $\\frac{R^2}{\\gamma^2}$ steps! \n",
    "\n",
    "Is this what you expect? Does this bound make sense intuitively?\n",
    "\n",
    "We can also obtain bounds on the number of updates when training on the sequence $\\mathbf{x}_1, \\ldots, \\mathbf{x}_T$ for the more general case of non-linearly separable data in terms of the hinge loss of our classifier! Another time, perhaps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
