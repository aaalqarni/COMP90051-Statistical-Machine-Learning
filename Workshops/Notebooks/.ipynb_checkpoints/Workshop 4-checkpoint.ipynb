{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP90051 Workshop 4\n",
    "## Logistic regression and gradient based training\n",
    "***\n",
    "\n",
    "In this workshop we'll be implementing logistic regression from scratch, using various techniques for gradient descent, namely batch gradient descent, stochastic gradient descent and BFGS, a quasi Newton method.\n",
    "\n",
    "First we'll import the relevant lirbaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.special import expit\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['figure.dpi'] = 108\n",
    "RND_SEED = 123456789"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Binary classification data\n",
    "Let's begin by generating some binary classification data.\n",
    "To make it easy for us to visualise the results, we'll stick to a two-dimensional feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples = 30, n_features = 2, n_informative=2, n_redundant=0, random_state=RND_SEED)\n",
    "X_b = np.column_stack((np.ones_like(y), X)) \n",
    "# add on a column of 1s, so that each instance includes a constant feature; accordingly the first weight is the bias term\n",
    "\n",
    "plt.scatter(X[y==0,0], X[y==0,1], color='b', label=\"$y = 0$\")\n",
    "plt.scatter(X[y==1,0], X[y==1,1], color='r', label=\"$y = 1$\")\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Question:** What do you notice about the data? It is possible for logistic regression to achieve perfect accuracy on this data?\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression\n",
    "In binary classification we receive training data $\\mathcal{D} = \\left((\\mathbf{x}_1, y_1), \\ldots, (\\mathbf{x}_n, y_n)\\right)$, where $\\mathbf{x}_k \\in \\mathbb{R}^m$ denotes the feature vector associated with the $k$th training point and the targets $y \\in \\{0,1\\}$. Logistic regression models the distribution of the binary target $y$ *conditional* on the feature vector $\\mathbf{x}$ as\n",
    "\n",
    "\\begin{equation}\n",
    "y | \\mathbf{x} \\sim \\mathrm{Bernoulli}[\\sigma(\\mathbf{w}^T \\mathbf{x})]\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathbf{w} \\in \\mathbb{R}^N$ is the weight vector (with bias term included) and $\\sigma(z) = 1/(1 + e^{-z})$ is the logistic function. Note here our object of interest is the conditional probability of a particular instance belonging to class 1 given observation of the associated feature vector $\\mathbf{x}$:\n",
    "\n",
    "$$p(y = 1 \\vert \\mathbf{x}) = \\sigma\\left(\\mathbf{w}^T \\mathbf{x}\\right) $$\n",
    " \n",
    "To find appropriate parameters $\\mathbf{w}$, we want to maximize the log-likelihood with respect to $\\mathbf{w}$, in lecture it was shown this is equivalent to minimization of the sum of cross-entropies over the instances ($i = 1,\\ldots,n$) in the training set\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{CE}(\\mathbf{v}; \\mathbf{x}, \\mathbf{y}) = -\\log \\prod_{i=1}^n p\\left(y_i \\vert \\mathbf{x}_i\\right) = - \\sum_{i = 1}^{n} \\left\\{ y_i \\log p(y=1 \\vert \\mathbf{x}_i) + (1 - y_i) \\log p (y=0 \\vert \\mathbf{x}_i) \\right\\}\n",
    "$$\n",
    "\n",
    "This quantity is also referred to as the *empirical risk*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### **Exercise:**\n",
    "Given we model the conditional probability of label $y=1$ to be $p(y = 1 \\vert \\mathbf{x}) = \\sigma\\left(\\mathbf{w}^T \\mathbf{x}\\right)$, show that prediction is based on a linear decision rule given by the sign of logarithm of the ratio of probabilities:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\log \\frac{p(y=1 \\vert \\mathbf{x})}{p(y=0 \\vert \\mathbf{x})} = \\mathbf{w}^T \\mathbf{x}\n",
    "\\end{equation}\n",
    "\n",
    "This is why logistic regression is referred to as a _log-linear model_. What is the decision boundary for logistic regression? \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to find a solution to this minimisation problem using gradient descent.\n",
    "\n",
    "Let's start by writing a function to compute the empirical risk, also known as the cross entropy loss, $\\mathcal{L}_{CE}$. We'll need to evaluate the risk later on to generate convergence plots, so we define a function for this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit # this is the logistic function\n",
    "sigmoid = expit\n",
    "\n",
    "def risk(w, X, y):\n",
    "    \"\"\"Evaluate the empirical risk under the cross-entropy (logistic) loss\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array of shape (n_samples, n_features)\n",
    "        Feature matrix. The matrix must contain a constant column to \n",
    "        incorporate a non-zero bias.\n",
    "        \n",
    "    y : array of shape (n_samples,)\n",
    "        Response relative to X. Binary classes must be encoded as 0 and 1.\n",
    "    \n",
    "    w : array of shape (n_features,)\n",
    "        Weight vector.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    risk : float\n",
    "    \"\"\"\n",
    "    prob_1 = sigmoid(X @ w) \n",
    "    cross_entropy = ... # fill in\n",
    "    return cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also need to be able to compute the _gradient_ of the empirical risk, in order to implement gradient descent. We will use the following result (if you're familiar with vector calculus, you may wish to derive this yourself):\n",
    "$$\n",
    "\\nabla_{\\mathbf{w}} \\mathcal{L}_{CE}(\\mathbf{w}) =  \\sum_{i = 1}^{n} \\left(\\sigma(\\mathbf{w}^T \\mathbf{x}_i) - y_i \\right)\\mathbf{x}_i\n",
    "$$\n",
    "\n",
    "The function below implements the above gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Exercise:** Complete the `grad_risk` function below, which computes $\\nabla_{\\mathbf{w}} \\mathcal{L}_{CE}(\\mathbf{w})$ for a given weight vector $\\mathbf{w}$ and training data $\\mathbf{X}$ and $\\mathbf{y}$.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_risk(w, X, y):\n",
    "    \"\"\"\n",
    "    Evaluate the gradient of the empirical risk\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array of shape (n_samples, n_features)\n",
    "        Feature matrix. The matrix must contain a constant column to \n",
    "        incorporate a non-zero bias.\n",
    "        \n",
    "    y : array of shape (n_samples,)\n",
    "        Response relative to X. Binary classes must be encoded as 0 and 1.\n",
    "    \n",
    "    w : array of shape (n_features,)\n",
    "        Weight vector.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    grad_w : array of shape (n_features,)\n",
    "    \"\"\"\n",
    "    # fill in \n",
    "    grad_w = ...\n",
    "    return grad_w\n",
    "\n",
    "# Test case\n",
    "if RND_SEED == 0:\n",
    "    test_grad_risk_actual = grad_risk(X_b, y, np.ones(3))\n",
    "    test_grad_risk_desired = np.array([0.11641865, -0.25260051, 0.20606407])\n",
    "    np.testing.assert_allclose(test_grad_risk_actual, test_grad_risk_desired)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll write a function to compute the solution through vanilla gradient descent. Recall that we follow the negative of the gradient in parameter space to update our parameters. Recall the basic update loop is as follows:\n",
    "\n",
    "$$ \\bf{w}^{(t+1)} = \\bf{w}^{(t)} - \\eta_t \\nabla_w \\mathcal{L}(\\bf{w}) $$\n",
    "\n",
    "Note that this simple procedure is the workhorse of many non-convex optimization programs, such as those used in modern neural network libraries. Contemporary libraries add more spice to the exact update, but the core idea of traversing some loss landscape in the direction of the negative gradient remains the same.\n",
    "\n",
    "Typically we halt when some stopping condition is reached, in this case we'll stop when the 2-norm of the difference between iterates drops below some threshold $\\epsilon$.\n",
    "\n",
    "$$ \\Vert \\bf{w}^{(t+1)} - \\bf{w}_{(t)} \\Vert^2 \\leq \\epsilon $$\n",
    "\n",
    "You could also use other stopping criteria, such as if the difference between two consecutive loss values drops below some threshold.\n",
    "\n",
    "***\n",
    "**Exercise:** Complete the `fit_logistic_GD` function below, which performs iterative gradient descent training.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_logistic_GD(X, y, w0, eta=0.01, iterations=100, tol=1e-5):\n",
    "    \"\"\"Performs iterative training using Gradient Descent\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array of shape (n_samples, n_features)\n",
    "        Feature matrix. The matrix must contain a constant column to \n",
    "        incorporate a non-zero bias.\n",
    "    \n",
    "    y : array of shape (n_samples,)\n",
    "        Response relative to X. Binary classes must be encoded as 0 and 1.\n",
    "    \n",
    "    w0 : array of shape (n_features,)\n",
    "        Current estimate of the weight vector.\n",
    "\n",
    "    eta : float\n",
    "        Learning rate, here a constant (but see notes below)\n",
    "    \n",
    "    max_iter : int\n",
    "        Maximum number of GD iterations \n",
    "    \n",
    "    tol : float\n",
    "        Stop when the 2-norm of the gradient falls below this value.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    w : list of arrays of shape (n_features,)\n",
    "        History of weight vectors.\n",
    "    \"\"\"    \n",
    "    w_history = [w0]\n",
    "    w = w0\n",
    "\n",
    "    for itr in range(iterations):\n",
    "        \n",
    "        grad_w = grad_risk(w, X, y) \n",
    "        w = ...  # fill in\n",
    "        w_history.append(w)\n",
    "        \n",
    "        # Stopping condition\n",
    "        if np.linalg.norm(grad_w) <= tol:\n",
    "            break\n",
    "        \n",
    "    print(\"Stopping after {} iterations\".format(itr+1))\n",
    "    print(\"2-norm of grad is {:.4g}\".format(np.linalg.norm(grad_w)))\n",
    "    print(\"Risk is {:.4g}\".format(risk(w, X, y)))\n",
    "\n",
    "    return w_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the algorithm on the 2D classification data we generated in Section 1 and visualise the result. Does the result look reasonable? Try adjusting the learning rate and seeing what effect this has on convergence. You may want to evaluate the contour plot below which provides a visualisation of the learning steps.\n",
    "\n",
    "*Note: we've chosen an arbitrary starting point for the weights, `w0`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_history_gd = fit_logistic_GD(X_b, y, w0=(1,4,2), eta=0.1)\n",
    "\n",
    "def plot_decision_boundary(X, y, w):\n",
    "    \"\"\"Plots the decision boundary of a logistic regression classifier defined \n",
    "    by weights `w`\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(X_b[y==0,1], X_b[y==0,2], color='b', label=\"$y = 0$\")\n",
    "    ax.scatter(X_b[y==1,1], X_b[y==1,2], color='r', label=\"$y = 1$\")\n",
    "    xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
    "    ax.plot(list(xlim), [-w[0]/w[2] - w[1]/w[2] * x for x in xlim], ls = \"-\", color=\"k\")\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.set_xlabel('$x_1$')\n",
    "    ax.set_ylabel('$x_2$')\n",
    "    ax.set_title(\"Decision boundary\")\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_decision_boundary(X_b, y, w_history_gd[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Question:** Is the solution what you expected? Is it a good fit for the data?\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the validity of our implementation by comparing with scikit-learn's implementation. Note that the scikit-learn implementation incorporates $L_2$ regularisation by default, so we need to switch it off by setting `penalty = 'none'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(penalty='none')\n",
    "clf.fit(X, y)\n",
    "w_sklearn = np.r_[clf.intercept_, clf.coef_.squeeze()]\n",
    "print(\"Weights according to GD: {}\".format(w_history_gd[-1]))\n",
    "print(\"Weights according to scikit-learn: {}\".format(w_sklearn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the path taken by the GD algorithm to reach the optimal solution.\n",
    "We plot the weight vectors at each iteration $\\mathbf{w}_0, \\mathbf{w}_1, \\ldots$ on top of contours of the empirical risk $\\mathcal{L}_{CE}(\\mathbf{w})$. \n",
    "The darker the shade, the lower the empirical risk. Note that we fix the bias term at its trained value, such that we can plot the objective surface in 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_iterates(X, y, w_history):\n",
    "    \"\"\"Plots the path of iterates in weight space (excluding the bias)\"\"\"\n",
    "    w_history = np.array(w_history)\n",
    "    \n",
    "    # Compute axes limits\n",
    "    w12_max = w_history[:,1:].max()\n",
    "    w12_min = w_history[:,1:].min()\n",
    "    w12_ran = w12_max - w12_min\n",
    "    border = 0.2\n",
    "    \n",
    "    # Compute objective on grid\n",
    "    w12 = np.linspace(w12_min - border * w12_ran, w12_max + border * w12_ran, num=100)\n",
    "    w1v, w2v = np.meshgrid(w12, w12)\n",
    "    w12v = np.c_[w1v.ravel(), w2v.ravel()]\n",
    "    z = np.array([risk(np.r_[w_history[-1][0], w12], X_b, y) for w12 in w12v])\n",
    "    z = z.reshape(w1v.shape)\n",
    "\n",
    "    plt.contourf(w1v, w2v, z)\n",
    "    plt.colorbar(label='Empirical risk')\n",
    "    plt.plot(w_history[:,1], w_history[:,2], c='c', ls='--')\n",
    "    plt.scatter(w_history[:,1], w_history[:,2], c='r', marker='.', label='Iterate')\n",
    "    plt.xlabel('$w_1$')\n",
    "    plt.ylabel('$w_2$')\n",
    "    plt.legend()\n",
    "    plt.title('Contour plot of iterates in weight space')\n",
    "    plt.show()\n",
    "\n",
    "plot_iterates(X_b, y, w_history_gd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic regression via BFGS\n",
    "\n",
    "Next, let's compare the GD algorithm with a more advanced second-order method of gradient descent.\n",
    "\n",
    "Gradient descent only uses first order derivative information to update parameters (it extrapolates from the current parameter value using a linear approximation to the function). Second-order methods such as [BFGS](https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm) can use the second-order derivative information to increase the rate of convergence. BFGS constructs an approximation to the Hessian matrix of second derivatives at each iteration, and uses this information to guide the next update. However such methods leveraging Hessian information tend to require a high space complexity and are only used for problems with a relatively low number of parameters.\n",
    "\n",
    "Now that we've implemented functions to compute the objective and the gradient, we can plug them into `fmin_bfgs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fmin_bfgs\n",
    "\n",
    "def fit_logistic_BFGS(X, y, w0):\n",
    "    w_history = [w0]\n",
    "    def display(w):\n",
    "        # Function for displaying progress\n",
    "        grad = grad_risk(w, X, y)\n",
    "        w_history.append(w)\n",
    "    \n",
    "    w = fmin_bfgs(f=risk, fprime=grad_risk, \n",
    "                  x0=w0, args=(X, y), disp=True, \n",
    "                  callback=display)\n",
    "    return w_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_history_bfgs = fit_logistic_BFGS(X_b, y, w0=(1,4,2))\n",
    "plot_decision_boundary(X_b, y, w_history_bfgs[-1])\n",
    "plot_iterates(X_b, y, w_history_bfgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now measure the accuracy of our trained model. To do so, we will first compute the predictions of the model. \n",
    "\n",
    "***\n",
    "**Exercise:** Complete the `get_predictions` function below which implements the decision function for logisitic regression, i.e., given inputs $\\mathbf{X}$ and parameters $\\mathbf{w}$, return a vector of classification labels for each instance. To do so, you will need to compute the $P(y=1|\\mathbf{x})$ for each instance, and threshold at 0.5. \n",
    "\n",
    "*Hint: you may want to use `np.where` to implement the threshold function.*\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def get_predictions(w, X):\n",
    "    #  Implement the logistic regression prediction rule here\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    w:       Weights, shape [m]\n",
    "    X:       Testing data, shape [N, m]\n",
    "    \n",
    "    Outputs:\n",
    "    y_pred:  Vector of predictions for given test instances\n",
    "    \"\"\"\n",
    "    # fill in\n",
    "    y_pred = ...\n",
    "    return y_pred\n",
    "\n",
    "y_pred = get_predictions(w_history_bfgs[-1], X_b)\n",
    "print('Accuracy achieved: {:.3f}'.format(accuracy_score(y, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Question:** What mistake was made above in this method of evaluating the predictive accuracy? Would you expect this result to generalise?\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Solving the minimization problem using SGD\n",
    "\n",
    "The above gradient optimisers have been *batch-based*, that is, they require the objective to be calculated in full, considering all the training points, and its corresponding gradient. For very large datasets and complex models, such as those used in deep learning, it can be desirable to use simpler methods which make more frequent updates and use few data points at each step. *Stochastic gradient descent (SGD)* is the simplest method for doing so, which uses only a single data point in estimating the gradient which is then used to make a gradient update.\n",
    "\n",
    "\n",
    "***\n",
    "**Exercise:** Complete the implementation of `fit_logistic_SGD` function below, which implements stochastic gradient descent, with batch size of 1. You can cut and paste from `fit_logisitic_GD` as a starting point.\n",
    "***\n",
    "Your job is to implement SGD. We won't worry about a sophisticated convergence test, as this is a bit more involved to design than before when we have exact gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_logistic_SGD(X, y, w0, eta=0.01, iterations=100):\n",
    "    w_history = [w0]\n",
    "    w = w0\n",
    "\n",
    "    for itr in range(iterations):\n",
    "        # fill in\n",
    "        ...\n",
    "        \n",
    "    return w_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_history_sgd = fit_logistic_SGD(X_b, y, w0=np.array((1,4,2)), eta=0.1)\n",
    "plot_decision_boundary(X_b, y, w_history_sgd[-1])\n",
    "plot_iterates(X_b, y, w_history_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly this isn't working perfectly, and after initial good progress the weights are bouncing around. This is due to the weight updates being too large. Experiment with a different learning rate, $\\eta$, to try and correct this behaviour. Set too low and it will not be too slow, and be terminated before getting near to the optimal parameters. Feel free to try a learning rate schedule where $\\eta$ changes with iteration, as suggested above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Question:** Is SGD a good fit to the problem of training a logistic regression model? Is it as efficient as the above methods?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Bonus: Linearly separable case (optional)\n",
    "\n",
    "\n",
    "**Exercise:** What happens when you re-run the notebook with `RND_SEED = 90051`?\n",
    "\n",
    "**Exercise:** Implement a L2 regularisation risk to the objective. This means changing the `risk` and `grad_risk` functions to use the regularised risk function, $\\mathcal{L}_{CE} + \\lambda \\mathbf{w}'\\mathbf{w}$, and its corresponding gradient, namely adding $\\lambda \\mathbf{w}$. Lambda is a hyperparameter which controls the extent of regularisation, and you might want to try out a few values to see its effect, e.g., 0.001, 0.01, 0.1 and 1. Using this new version of logistic regression, how does your answer to the above question change?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
